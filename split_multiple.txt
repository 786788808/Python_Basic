import unittest
import os
import sys
import shutil
import tempfile
import json
import pandas as pd
import logging
from datetime import datetime, timedelta
from unittest.mock import patch, MagicMock

# 获取项目根目录
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# 添加项目路径到系统路径
sys.path.append(PROJECT_ROOT)

# 获取测试数据目录
MOCK_DATA_DIR = os.path.join(
    PROJECT_ROOT, 
    'tests', 
    'test_dags', 
    'app', 
    'mock_data', 
    'HKEx_Suspension'
)

# 检查测试数据目录是否存在
if not os.path.exists(MOCK_DATA_DIR):
    os.makedirs(MOCK_DATA_DIR, exist_ok=True)

# 设置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TestHKExSuspension(unittest.TestCase):
    
    @classmethod
    def setUpClass(cls):
        """类级别的设置，只执行一次"""
        # 创建模拟配置文件（如果不存在）
        cls.create_mock_config_files()
        
        # 确保测试数据目录存在
        os.makedirs(MOCK_DATA_DIR, exist_ok=True)
        
        # 创建模拟测试数据文件
        cls.create_mock_data_files()
    
    @classmethod
    def tearDownClass(cls):
        """类级别的清理"""
        # 可以在这里清理测试数据，但通常保留以便检查
        pass
    
    @classmethod
    def create_mock_config_files(cls):
        """创建模拟配置文件"""
        # 项目根目录
        project_root = PROJECT_ROOT
        
        # 创建env.json（如果不存在）
        env_path = os.path.join(project_root, 'env.json')
        if not os.path.exists(env_path):
            env_data = {
                "gcp_env": {
                    "proxy": "https://proxy.example.com"
                }
            }
            with open(env_path, 'w') as f:
                json.dump(env_data, f)
            logger.info(f"Created mock env.json at {env_path}")
        
        # 创建webS_HKExSuspension.json（如果不存在）
        param_path = os.path.join(project_root, 'webS_HKExSuspension.json')
        if not os.path.exists(param_path):
            param_data = {
                "file_dir": os.path.join(project_root, "data", "web3", "HKEx_Suspension"),
                "log_dir": os.path.join(project_root, "logs", "HKEx_Suspension"),
                "file_url": "https://www1.hkexnews.hk/search/titlesearch.xhtml?lang=en"
            }
            with open(param_path, 'w') as f:
                json.dump(param_data, f)
            logger.info(f"Created mock webS_HKExSuspension.json at {param_path}")
    
    @classmethod
    def create_mock_data_files(cls):
        """创建模拟测试数据文件（如果不存在）"""
        base_name = "HKExSuspension_20250701"
        
        # 创建HTML和CSV文件
        for suffix in ["TradingHalt", "Suspension", "Resumption"]:
            html_file = f"{suffix}_20250701.html"
            csv_file = f"{suffix}_20250701.csv"
            
            html_path = os.path.join(MOCK_DATA_DIR, html_file)
            csv_path = os.path.join(MOCK_DATA_DIR, csv_file)
            
            # 创建HTML文件
            if not os.path.exists(html_path):
                with open(html_path, 'w') as f:
                    f.write("<html><body>Mock HTML content</body></html>")
            
            # 创建CSV文件
            if not os.path.exists(csv_path):
                df = pd.DataFrame({
                    "Release_time": ["2025-07-01 09:30:00"],
                    "Stock_code": ["00001"],
                    "Short_stock_name": ["CK HUTCHISON"],
                    "Doc_url": ["https://example.com/doc"],
                    "Susp_status": ["Halt"]
                })
                df.to_csv(csv_path, index=False)
        
        # 创建合并的CSV文件
        combined_path = os.path.join(MOCK_DATA_DIR, "HKExSuspension_20250701.csv")
        if not os.path.exists(combined_path):
            combined_df = pd.DataFrame({
                "Release_time": ["2025-07-01 09:30:00", "2025-07-01 10:15:00"],
                "Stock_code": ["00001", "00002"],
                "Short_stock_name": ["CK HUTCHISON", "CLP HOLDINGS"],
                "Doc_url": ["https://example.com/doc1", "https://example.com/doc2"],
                "Susp_status": ["Halt", "Suspended"]
            })
            combined_df.to_csv(combined_path, index=False)
    
    def test_date_range_function(self):
        """测试日期范围生成函数"""
        # 模拟的日期范围函数
        def define_data_start_end_date(loading_type, order_date):
            if loading_type == 'daily':
                date_obj = datetime.strptime(order_date, '%Y%m%d')
                from_date = date_obj.replace(day=1).strftime('%Y%m%d')
                _, last_day = calendar.monthrange(date_obj.year, date_obj.month)
                to_date = date_obj.replace(day=last_day).strftime('%Y%m%d')
                return [[from_date, to_date]]
            elif loading_type == 'initial_load':
                # 简化实现用于测试
                return [['19990401', '19990430'], ['19990501', '19990531']]
            else:
                raise ValueError("Invalid loading_type")
        
        # 测试daily模式
        result = define_data_start_end_date('daily', '20230115')
        self.assertEqual(result, [['20230101', '20230131']])
        
        # 测试initial_load模式
        result = define_data_start_end_date('initial_load', '19990515')
        self.assertEqual(len(result), 2)
    
    def test_config_class(self):
        """测试配置类"""
        # 模拟的配置类
        class HKExSuspConfig:
            def __init__(self, gcp_env, order_date, from_date, to_date):
                self.file_date = from_date
                self.file_dir_date = os.path.join(
                    MOCK_DATA_DIR, 
                    f"{from_date}_{order_date}"
                )
                os.makedirs(self.file_dir_date, exist_ok=True)
                
                self.document_types = ["Trading Halt", "Suspension", "Resumption"]
                self.txcode = ['1966', '7368', '2165']
                self.susp_status_list = ["7", "5", "4"]
                
                self.html_filename = [
                    f"TradingHalt_{from_date}.html",
                    f"Suspension_{from_date}.html",
                    f"Resumption_{from_date}.html"
                ]
                
                self.csv_filename = [
                    f"TradingHalt_{from_date}.csv",
                    f"Suspension_{from_date}.csv",
                    f"Resumption_{from_date}.csv"
                ]
                
                self.html_paths = [
                    os.path.join(self.file_dir_date, f) 
                    for f in self.html_filename
                ]
                
                self.csv_paths = [
                    os.path.join(self.file_dir_date, f) 
                    for f in self.csv_filename
                ]
        
        # 测试配置类
        config = HKExSuspConfig("test_env", "20250701", "20250601", "20250630")
        
        # 验证属性
        self.assertEqual(config.file_date, "20250601")
        self.assertEqual(len(config.html_paths), 3)
        self.assertTrue(os.path.exists(config.file_dir_date))
        
        # 清理
        shutil.rmtree(config.file_dir_date)
    
    def test_data_processing(self):
        """测试数据处理函数"""
        # 创建测试数据
        test_data = pd.DataFrame({
            'Stock_code': ['00001', '00002+++00003', '00004', '00005+++00006'],
            'Short_stock_name': ['COMPANY A', 'COMPANY B', 'COMPANY C+++COMPANY D', 'COMPANY E'],
            'Other_column': [1, 2, 3, 4]
        })
        
        # 模拟的数据处理函数
        def split_multiple_stock_stockname(df):
            expanded_rows = []
            for _, row in df.iterrows():
                stock_code = str(row['Stock_code'])
                stock_name = str(row['Short_stock_name'])
                
                codes = [c.strip() for c in stock_code.split('+++')]
                names = [n.strip() for n in stock_name.split('+++')]
                
                min_len = min(len(codes), len(names))
                for i in range(min_len):
                    new_row = row.copy()
                    new_row['Stock_code'] = codes[i]
                    new_row['Short_stock_name'] = names[i]
                    expanded_rows.append(new_row)
            
            return pd.DataFrame(expanded_rows)
        
        # 处理数据
        result = split_multiple_stock_stockname(test_data)
        
        # 验证结果
        self.assertEqual(len(result), 6)
        self.assertEqual(list(result['Stock_code']), 
                         ['00001', '00002', '00003', '00004', '00005', '00006'])
    
    def test_parse_html_file(self):
        """测试HTML解析函数"""
        # 使用实际测试数据
        html_path = os.path.join(MOCK_DATA_DIR, "TradingHalt_20250701.html")
        
        # 模拟的解析函数
        def parse_html(file_path):
            # 实际实现中会使用lxml解析
            # 这里简化为返回模拟数据
            return pd.DataFrame({
                "Release_time": ["2025-07-01 09:30:00"],
                "Stock_code": ["00001"],
                "Short_stock_name": ["CK HUTCHISON"],
                "Doc_url": ["https://example.com/doc"],
                "Susp_status": ["Halt"]
            })
        
        # 解析文件
        df = parse_html(html_path)
        
        # 验证结果
        self.assertEqual(len(df), 1)
        self.assertEqual(df.iloc[0]['Stock_code'], "00001")
    
    def test_combine_csv_files(self):
        """测试合并CSV文件功能"""
        # 获取所有CSV文件路径
        csv_files = [
            os.path.join(MOCK_DATA_DIR, f)
            for f in os.listdir(MOCK_DATA_DIR)
            if f.endswith('.csv') and not f.startswith('HKExSuspension')
        ]
        
        # 模拟的合并函数
        def combine_csv_files(file_paths):
            dfs = []
            for file_path in file_paths:
                df = pd.read_csv(file_path)
                dfs.append(df)
            return pd.concat(dfs, ignore_index=True)
        
        # 合并文件
        combined_df = combine_csv_files(csv_files)
        
        # 验证结果
        self.assertGreater(len(combined_df), 0)
        self.assertEqual(len(combined_df['Stock_code'].unique()), 1)
        
        # 保存合并结果（可选）
        output_path = os.path.join(MOCK_DATA_DIR, "combined_output.csv")
        combined_df.to_csv(output_path, index=False)
        self.assertTrue(os.path.exists(output_path))

if __name__ == '__main__':
    unittest.main()
